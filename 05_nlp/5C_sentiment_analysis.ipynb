{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5C) Sentiment analysis\n",
    "\n",
    "Sentiment analysis is widely used as a way of measuring the positivity or negativity of sentences. It has a lot of corporate uses–companies want to know how its products are being reviewed, for instance–as well as political uses—candidates want to know how they're being talked about on Twitter, say. But we can also imagine literary uses: how are characters being described? Does sentiment change over time in the novel? Here's some tools to do sentiment analysis.\n",
    "\n",
    "#### Install \n",
    "For this notebook, you'll need to install vaderSentiment:\n",
    "\n",
    "    pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some imports\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can I get the sentiment of sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment_analysis_textblob(string):\n",
    "    # first make a blob\n",
    "    blob = TextBlob(string)\n",
    "\n",
    "    # make output dictionary\n",
    "    output_list = []\n",
    "    \n",
    "    # for each sentence\n",
    "    sent_num=0\n",
    "    for sent in blob.sentences:\n",
    "        sent_num+=1\n",
    "        \n",
    "        # make an empty results dictionary\n",
    "        result_dict={}\n",
    "        result_dict['_sent_num'] = sent_num\n",
    "        result_dict['_sent'] = str(sent)\n",
    "        \n",
    "        result_dict['polarity'] = sent.sentiment.polarity\n",
    "        result_dict['subjectivity'] = sent.sentiment.subjectivity\n",
    "        \n",
    "        output_list.append(result_dict)\n",
    "    \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juliet=\"\"\"\n",
    "But soft, what light through yonder window breaks?\n",
    "It is the east, and Juliet is the sun.\n",
    "Arise, fair sun, and kill the envious moon.\n",
    "Who is already sick and pale with grief\n",
    "That thou, her maid, art far more fair than she.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sentiment_analysis_textblob(juliet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) polyglot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Polyglot](https://polyglot.readthedocs.io/) can also do sentiment analysis, and in multiple languages.\n",
    "\n",
    "To install:\n",
    "\n",
    "    conda install -c conda-forge pyicu\n",
    "    pip install pycld2\n",
    "    pip install morfessor\n",
    "    pip install polyglot\n",
    "    polyglot download LANG:en   # for english\n",
    "    polyglot download LANG:es   # for spanish (optional)\n",
    "    polyglot download LANG:xx   # where xx is the two-letter language code\n",
    "   \n",
    "See [the website](https://polyglot.readthedocs.io/) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_polyglot(string):\n",
    "    # let's try this...\n",
    "    try:\n",
    "        # to use polyglot, import its \"Text\" object:\n",
    "        from polyglot.text import Text\n",
    "    except ImportError:\n",
    "        print('Polyglot not installed! To do so, follow the instructions above.')\n",
    "        return\n",
    "    # from here on we can assume that polyglot is imported\n",
    "    \n",
    "    # wrap that Text object around any string\n",
    "    pg_text = Text(string)\n",
    "\n",
    "    # make an output list\n",
    "    output_list = []\n",
    "    \n",
    "    # loop over sentences\n",
    "    sent_num = 0\n",
    "    for sent in pg_text.sentences:\n",
    "        sent_num+=1\n",
    "\n",
    "        # make an empty results dictionary\n",
    "        result_dict={}\n",
    "        result_dict['_sent_num'] = sent_num\n",
    "        result_dict['_sent'] = str(sent)\n",
    "        \n",
    "        # make a new text (maybe this sentence is in a different language?)\n",
    "        sent2 = Text(str(sent))\n",
    "        \n",
    "        result_dict['polarity'] = sent2.polarity\n",
    "\n",
    "        # add to output\n",
    "        output_list.append(result_dict)\n",
    "        \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sentiment_analysis_polyglot(\"\"\"\n",
    "I have a horrible dog named Spot who is honestly the worst creature on the entire planet.\n",
    "I have a dog named Spot who is honestly NOT the worst creature on the entire planet.\n",
    "Tengo un perro horrible que honestamente es la peor criatura en todo el planeta.\n",
    "I have an OK dog named Spot who is honestly a pretty good creature.\n",
    "Tengo un perro horrible que honestamente es la peor criatura en todo el planeta.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) VADER (recommended)\n",
    "\n",
    "From the [source for vaderSentiment](https://github.com/cjhutto/vaderSentiment):\n",
    "\n",
    "<blockquote>VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It is fully open-sourced under the MIT License.</blockquote>\n",
    "\n",
    "For more information, see this [post on sentiment analysis](https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vader_scores(string):\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    score = analyser.polarity_scores(string)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it out\n",
    "get_vader_scores(\"I have a horrible dog named Spot who is honestly the worst creature on the entire planet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we trick it?\n",
    "get_vader_scores(\"I have a NOT SO horrible dog named Spot who is honestly NOT the worst creature on the entire planet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function for sentiment analysis with VADER\n",
    "\n",
    "def sentiment_analysis_vader(string):\n",
    "    blob = TextBlob(string)\n",
    "\n",
    "    # make output dictionary\n",
    "    output_list = []\n",
    "    \n",
    "    # for each sentence\n",
    "    sent_num=0\n",
    "    for sent in blob.sentences:\n",
    "        # add 1 to number of sentence\n",
    "        sent_num+=1\n",
    "        \n",
    "        # print sent_num if it's divisible by 100\n",
    "        if not sent_num%100: print(sent_num, len(blob.sentences))\n",
    "        \n",
    "        # make an empty results dictionary\n",
    "        result_dict={}\n",
    "        \n",
    "        # store sent num to it\n",
    "        result_dict['_sent_num'] = sent_num\n",
    "        \n",
    "        # store the sentence to it\n",
    "        result_dict['_sent'] = str(sent)\n",
    "        \n",
    "        # get the score dictionary\n",
    "        vader_scores = get_vader_scores(sent)\n",
    "        \n",
    "        # loop over the scores dictionary\n",
    "        for key,value in vader_scores.items():\n",
    "            # assign the score to the result dictionary\n",
    "            result_dict[key]=value\n",
    "            \n",
    "        # add result dictionary to output_list\n",
    "        output_list.append(result_dict)\n",
    "    \n",
    "    # return output list\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sentiment_analysis_vader(juliet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run it on Harry Potter\n",
    "with open('../corpora/harry_potter/texts/Sorcerers Stone.txt') as file:\n",
    "    txt=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment_harrypotter = pd.DataFrame(sentiment_analysis_vader(txt))\n",
    "df_sentiment_harrypotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment_harrypotter.sort_values('compound',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show preponderance of negativity\n",
    "df_sentiment_harrypotter.plot(x='_sent_num', y='neg',figsize=(24,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's going on in the negative region?\n",
    "df_sentiment_harrypotter.query('1000 < _sent_num < 1400').sort_values('compound')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For sentiment analysis research team\n",
    "\n",
    "* Research sentiment analysis in all of Tropic of Orange:\n",
    "    * Run the VADER sentiment analyzer on all of Tropic of Orange (see below)\n",
    "    * Merge that dataframe with the Tropic of Orange metadata\n",
    "    * Save the merged dataframe to excel\n",
    "    * Open it in Tableau and generate a few graphs. Which are the narrators with the most pos/neg sentiment? Who has the highest emotional range?\n",
    "\n",
    "\n",
    "* (Advanced) Calculate the sentiment only for sentences in which places are mentioned (expand on Tuesday's work).\n",
    "    * Merge this dataframe with the Tropic of Orange metadata\n",
    "    * Merge in Tableau or in pandas that dataframe with the lat/long data from Tuesday\n",
    "    * Map the emotionality of places\n",
    "    \n",
    "    \n",
    "* (Advanced) Calculate the sentiment only for sentences in which people are mentioned\n",
    "    * Merge with Tropic of Orange metadata, save\n",
    "    * Plot in Tableau\n",
    "    * Who are the most positively/negatively *mentioned* people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## @TODO: Get the sentiment for every sentence in the entire Tropic of Orange text\n",
    "#\n",
    "\n",
    "# Load the dataframe for Tropic of Orange\n",
    "df_tropic = pd.read_excel('../corpora/tropic_of_orange/metadata.xls')\n",
    "\n",
    "# make an empty list for all results in the book\n",
    "all_results = []\n",
    "\n",
    "# set a variable to the text folder\n",
    "text_folder = '../corpora/tropic_of_orange/texts'\n",
    "\n",
    "\n",
    "# loop over the filename column in df_tropic...      \n",
    "\n",
    "    # print filename\n",
    "    \n",
    "\n",
    "    # get full path\n",
    "    \n",
    "    \n",
    "    # open text\n",
    "    \n",
    "        \n",
    "    # call one of the sentiment analysis functions to get back a list of dictionaries\n",
    "    \n",
    "    \n",
    "    # for each result dictionary in that list\n",
    "    \n",
    "        # add the filename to the result dictionary\n",
    "        \n",
    "        # append the result dictionary to all_results\n",
    "        \n",
    "\n",
    "# make a data frame from all of the results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
