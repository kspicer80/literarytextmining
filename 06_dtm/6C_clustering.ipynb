{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "How can we \"cluster\" texts together based on similar vocabulary, or other features we calculate?\n",
    "\n",
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some things\n",
    "import os\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option(\"display.max_rows\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set text folder and metadata path\n",
    "\n",
    "text_folder = '../corpora/tropic_of_orange/texts'\n",
    "path_to_metadata='../corpora/tropic_of_orange/metadata.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "df_meta = pd.read_excel(path_to_metadata)\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a label column\n",
    "labels = []\n",
    "for index,row in df_meta.iterrows():\n",
    "    first_name_of_narrator = row['narrator'].split()[0]\n",
    "    label = first_name_of_narrator+' ('+str(row['chapter'])+')'\n",
    "    labels.append(label)\n",
    "df_meta['label']=labels\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also set the 'label' as the index\n",
    "df_meta=df_meta.set_index('label',drop=False)    # drop=False means that 'label' is preserved as a column, as well as acting as the new index\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to make a document-term matrix\n",
    "# FROM a df_meta object\n",
    "\n",
    "def make_dtm_from_df(df_meta,n_top_words=1000,normalize=True,filename_col='fn',no_cap_words=True,exclude_words=[]):\n",
    "    # get stopwords\n",
    "    stopwords=exclude_words\n",
    "    stopwords=set(stopwords)\n",
    "\n",
    "    # make an empty results list\n",
    "    all_results = []\n",
    "\n",
    "    # make a count for all words\n",
    "    from collections import Counter\n",
    "    all_counts = Counter()\n",
    "\n",
    "    # for each filename\n",
    "    for i,fn in enumerate(df_meta[filename_col]):\n",
    "        if not i%10: print('>> looping through #',i,'of',len(df_meta),'files:',fn)\n",
    "        # make sure is a text file\n",
    "        if not fn.endswith('.txt'): continue\n",
    "        \n",
    "        # full path\n",
    "        full_path = os.path.join(text_folder,fn)\n",
    "\n",
    "        # open the file\n",
    "        with open(full_path) as file:\n",
    "            txt=file.read()\n",
    "\n",
    "        # make a blob\n",
    "        blob = TextBlob(txt)\n",
    "\n",
    "        # make a result dictionary\n",
    "        text_result = {}\n",
    "\n",
    "        # set the filename and index\n",
    "        text_result['fn']=fn\n",
    "        text_result['index']=df_meta.index[i]\n",
    "\n",
    "        # loop over the word counts\n",
    "        num_words = len(blob.words)\n",
    "        \n",
    "        from collections import Counter\n",
    "        word_counts = Counter(blob.words)\n",
    "\n",
    "        # for each word,count pair in the blob.word_counts dictionary...\n",
    "        for word,count in word_counts.items():\n",
    "            # is the word in the stopwords?\n",
    "            if word in stopwords: continue  \n",
    "                \n",
    "            # skip capitalized words?\n",
    "            if no_cap_words and word!=word.lower(): continue\n",
    "                \n",
    "            # lowercase word\n",
    "            word = word.lower()\n",
    "\n",
    "            # is the word a punctuation?\n",
    "            if not word[0].isalpha(): continue\n",
    "            \n",
    "            # set the normalized version\n",
    "            if normalize:\n",
    "                # get the term frequency (count divided by number of words)\n",
    "                tf = count / num_words\n",
    "\n",
    "                # set the term frequency result to the key 'word' in the text_result dictionary\n",
    "                text_result[word] = tf\n",
    "            else:\n",
    "                # set the count as a result\n",
    "                text_result[word] = count\n",
    "\n",
    "            # add the count to the dictionary of counts for all words\n",
    "            all_counts[word]+=count\n",
    "\n",
    "        # add results\n",
    "        all_results.append(text_result)\n",
    "    \n",
    "    # Get the most frequent words\n",
    "    most_common_words_plus_counts = all_counts.most_common(n_top_words)\n",
    "    \n",
    "    # Get only the words\n",
    "    word_columns = []\n",
    "    for word,count in most_common_words_plus_counts:\n",
    "        word_columns.append(word)\n",
    "        \n",
    "    # Words used as columns\n",
    "    print('>> top',n_top_words,'words:',word_columns)\n",
    "    \n",
    "    # Get columns\n",
    "    columns=[]\n",
    "    #columns.append('fn')\n",
    "    columns.append('index')\n",
    "    columns.extend(word_columns)\n",
    "    \n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame(all_results, columns=columns).set_index('index').fillna(0) * 1000\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add anything to stopwords?\n",
    "stopword_list.append('us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the document term matrix\n",
    "dtm = make_dtm_from_df(df_meta,normalize=True,n_top_words=500,exclude_words=stopword_list,no_cap_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with metadata\n",
    "dtm_meta = df_meta.join(dtm,lsuffix='_meta')           # join because both indices are identical\n",
    "dtm_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance matrix\n",
    "\n",
    "We can think about \"distance\" between documents in the DTM space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-D distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/15910019/annotate-data-points-while-plotting-from-pandas-dataframe/15911372#15911372\n",
    "\n",
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        ax.text(point['x'], point['y'], str(point['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot(df, x_col, y_col, label_col=None):\n",
    "    max_x=max(df[x_col])\n",
    "    max_y=max(df[y_col])\n",
    "    ax = df.plot(x=x_col,y=y_col,kind='scatter',xlim=(0,max_x),ylim=(0,max_y),figsize=(10,10))\n",
    "    if label_col:\n",
    "        label_point(df[x_col], df[y_col], df[label_col], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biplot(dtm_meta,'said','knew','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot_groups(df, x_col, y_col, group_col=None, label_col=None, figsize=(10,10)):\n",
    "    max_x=max(df[x_col])\n",
    "    max_y=max(df[y_col])\n",
    "    \n",
    "    groups = df.groupby(group_col)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "    for name, group in groups:\n",
    "        ax.plot(group[x_col], group[y_col], marker='o', linestyle='', ms=8, label=name)\n",
    "        label_point(group[x_col], group[y_col], group[label_col], ax)\n",
    "        #ax.plot(x=group[x_col],y=group[y_col],kind='scatter',xlim=(0,max_x),ylim=(0,max_y),label=\"hello\")\n",
    "    ax.legend()\n",
    "    plt.xlabel(x_col, fontsize=16)\n",
    "    plt.ylabel(y_col, fontsize=16)\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biplot_groups(dtm_meta, 'said', 'knew', 'narrator', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_2d = dtm[['said','knew']]\n",
    "dtm_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting distances:\n",
    "# for more info on pdist: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html\n",
    "\n",
    "#pdist(dtm)\n",
    "#squareform(pdist(dtm))\n",
    "#pd.DataFrame(squareform(pdist(dtm)))\n",
    "#pd.DataFrame(squareform(pdist(dtm)), columns=dtm.index, index=dtm.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dist(X_dtm,dist_metric='euclidean',standardize=False):\n",
    "    distmatrix=pdist(X_dtm,metric=dist_metric)\n",
    "    return pd.DataFrame(squareform(distmatrix), columns=X_dtm.index, index=X_dtm.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_2d_dist = make_dist(dtm_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_2d_dist['Rafaela (1)'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-D Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many dimensions?\n",
    "len(dtm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance matrix\n",
    "\n",
    "dtm_dist = make_dist(dtm)\n",
    "dtm_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_dist['Rafaela (1)'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_dist['Bobby (2)'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_dist['Manzanar (19)'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_dist['Manzanar (5)'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it is: in a single line, compute a hierarchical clustering of the DTM\n",
    "\n",
    "hclust = linkage(dtm,method='complete')\n",
    "hclust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fancy_dendrogram(*args, **kwargs):\n",
    "    max_d = kwargs.pop('max_d', None)\n",
    "    if max_d and 'color_threshold' not in kwargs:\n",
    "        kwargs['color_threshold'] = max_d\n",
    "    annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "    ddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "    if not kwargs.get('no_plot', False):\n",
    "        plt.title('Hierarchical Clustering Dendrogram')\n",
    "        plt.xlabel('sample index or (cluster size)')\n",
    "        plt.ylabel('distance')\n",
    "        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "            x = 0.5 * sum(i[1:3])\n",
    "            y = d[1]\n",
    "            if y > annotate_above:\n",
    "                plt.plot(x, y, 'o', c=c)\n",
    "                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
    "                             textcoords='offset points',\n",
    "                             va='top', ha='center')\n",
    "        if max_d:\n",
    "            plt.axhline(y=max_d, c='k')\n",
    "    return ddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(dtm,linkage_method='complete'):\n",
    "    hclust = linkage(dtm,method=linkage_method)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 8))\n",
    "    plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('distance')\n",
    "    fancy_dendrogram(\n",
    "        hclust,\n",
    "        show_leaf_counts=False,  # otherwise numbers in brackets are counts\n",
    "        leaf_rotation=90.,\n",
    "        leaf_font_size=12.,\n",
    "        show_contracted=True,  # to get a distribution impression in truncated branches\n",
    "        labels=dtm.index,\n",
    "    )\n",
    "    plt.savefig('hclust_dendrogram.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dendrogram(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF function\n",
    "def to_tfidf(dtm):\n",
    "    import numpy as np, pandas as pd\n",
    "    # list of dictionaries\n",
    "    dtm_tfidf = pd.DataFrame()\n",
    "    \n",
    "    for word in dtm.columns:\n",
    "        # tf\n",
    "        tf_series = dtm[word]\n",
    "        \n",
    "        # idf\n",
    "        num_docs = len(dtm)\n",
    "        num_docs_with_word=len(dtm[dtm[word]>0])\n",
    "        idf=np.log(num_docs/num_docs_with_word)\n",
    "        \n",
    "        # tfidf\n",
    "        tfidf_series = tf_series * idf\n",
    "        dtm_tfidf[word]=tfidf_series\n",
    "    \n",
    "    return dtm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf = to_tfidf(dtm)\n",
    "dtm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf.loc['Manzanar (46)'].nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf.loc['Arcangel (36)'].nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf.loc['Bobby (49)'].nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf.loc['Gabriel (6)'].nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf.loc['Gabriel (17)'].nlargest(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "\n",
    "[t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) is a popular method of [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction). For more information, [see here](https://www.datacamp.com/community/tutorials/introduction-t-sne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne(datadf,df_dist=None,n_components=2,resultdf=None):\n",
    "    if df_dist is None: df_dist=make_dist(datadf)\n",
    "    m_dist=df_dist.values\n",
    "    from sklearn.manifold import TSNE\n",
    "    model = TSNE(n_components=n_components, random_state=0)\n",
    "    fit = model.fit_transform(m_dist)\n",
    "    from collections import defaultdict\n",
    "    newcols=defaultdict(list)\n",
    "    for i,word in enumerate(datadf.index):\n",
    "        for ii,xx in enumerate(fit[i]):\n",
    "            newcols['tsne_V'+str(ii+1)] += [xx]\n",
    "    if resultdf is None: resultdf=pd.DataFrame(index=datadf.index)\n",
    "    for k,v in list(newcols.items()): resultdf[k]=v\n",
    "    return resultdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tsne = tsne(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tsne_meta = dtm_tsne.join(dtm_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biplot_groups(dtm_tsne_meta, 'tsne_V1', 'tsne_V2', 'narrator', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
