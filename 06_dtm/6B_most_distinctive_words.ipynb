{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most distinctive words\n",
    "\n",
    "Following on [the previous notebook](6A_document_term_matrices.ipynb)...\n",
    "\n",
    "How can we find the words directly which distinguish Republican and Democrat States of the Union? Or between pre- and post-war America?\n",
    "\n",
    "\n",
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some things\n",
    "import os\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "pd.set_option(\"display.max_rows\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set text folder and metadata path\n",
    "# (If you don't have this corpus, please download it here): https://www.dropbox.com/sh/xd854hgyvbysqlm/AAAhbS6r7MFe4SVg1BFuuMTCa?dl=1\n",
    "\n",
    "text_folder = '../corpora/sotu_1900-2018/texts'\n",
    "path_to_metadata='../corpora/sotu_1900-2018/metadata.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions from last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each of the filenames\n",
    "\n",
    "def make_dtm(text_folder,n_top_words=1000,normalize=False):\n",
    "    # get stopwords\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords=set(stopwords.words('english'))\n",
    "\n",
    "    # make an empty results list\n",
    "    all_results = []\n",
    "\n",
    "    # make a count for all words\n",
    "    from collections import Counter\n",
    "    all_counts = Counter()\n",
    "\n",
    "    # for each filename\n",
    "    filenames=sorted(os.listdir(text_folder))\n",
    "    for i,fn in enumerate(filenames):\n",
    "        if not i%10: print('>> looping through #',i,'of',len(filenames),'files:',fn)\n",
    "        # make sure is a text file\n",
    "        if not fn.endswith('.txt'): continue\n",
    "        \n",
    "        # full path\n",
    "        full_path = os.path.join(text_folder,fn)\n",
    "\n",
    "        # open the file\n",
    "        with open(full_path) as file:\n",
    "            txt=file.read()\n",
    "\n",
    "        # make a blob\n",
    "        blob = TextBlob(txt.lower())\n",
    "\n",
    "        # make a result dictionary\n",
    "        text_result = {}\n",
    "\n",
    "        # set the filename\n",
    "        text_result['fn']=fn\n",
    "\n",
    "        # loop over the word counts\n",
    "        num_words = len(blob.words)\n",
    "\n",
    "        # for each word,count pair in the blob.word_counts dictionary...\n",
    "        for word,count in blob.word_counts.items():\n",
    "            # is the word in the stopwords?\n",
    "            if word in stopwords: continue  \n",
    "\n",
    "            # is the word a punctuation?\n",
    "            if not word[0].isalpha(): continue\n",
    "            \n",
    "            # set the normalized version\n",
    "            if normalize:\n",
    "                # get the term frequency (count divided by number of words)\n",
    "                tf = count / num_words\n",
    "\n",
    "                # set the term frequency result to the key 'word' in the text_result dictionary\n",
    "                text_result[word] = tf\n",
    "            else:\n",
    "                # set the count as a result\n",
    "                text_result[word] = count\n",
    "\n",
    "            # add the count to the dictionary of counts for all words\n",
    "            all_counts[word]+=count\n",
    "\n",
    "        # add results\n",
    "        all_results.append(text_result)\n",
    "    \n",
    "    # Get the most frequent words\n",
    "    most_common_words_plus_counts = all_counts.most_common(n_top_words)\n",
    "    \n",
    "    # Get only the words\n",
    "    word_columns = []\n",
    "    for word,count in most_common_words_plus_counts:\n",
    "        word_columns.append(word)\n",
    "    \n",
    "    # Get columns\n",
    "    columns=[]\n",
    "    columns.append('fn')\n",
    "    columns.extend(word_columns)\n",
    "    \n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame(all_results, columns=columns).set_index('fn').fillna(0)\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the document term matrix\n",
    "dtm = make_dtm(text_folder,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata for this corpus\n",
    "df_meta = pd.read_excel(path_to_metadata).set_index('fn')\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the metadata\n",
    "dtm_meta=df_meta.merge(dtm,on='fn')\n",
    "dtm_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most distinctive words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Difference of means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_meta.groupby('Party').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_meta.groupby('Party').mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(dtm_meta.groupby('Party').mean().T * 1000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_meta_T = dtm_meta.groupby('Party').mean().T * 1000\n",
    "dtm_meta_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_meta_T['D-R']=dtm_meta_T['Democrat'] - dtm_meta_T['Republican']\n",
    "round(dtm_meta_T,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(dtm_meta_T.sort_values('D-R'),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_meta.boxplot('government',by='Party',figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_meta.boxplot('war',by='Party',figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_meta.sort_values('war',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by government\n",
    "dtm_meta.sort_values('government',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is Nixon using government so much?\n",
    "nixon_path = os.path.join(text_folder, '1971.Nixon.txt')\n",
    "print(nixon_path)\n",
    "\n",
    "# Open the file\n",
    "with open(nixon_path) as file:\n",
    "    nixon_txt=file.read()\n",
    "    \n",
    "# make nltk version of the text (useful for concordance)\n",
    "import nltk\n",
    "nixon_words = nltk.word_tokenize(nixon_txt)\n",
    "nixon_nltk = nltk.text.Text(nixon_words)\n",
    "\n",
    "# get concordance\n",
    "nixon_nltk.concordance('government',width=100,lines=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(text_folder,filename,word,width=100,lines=1000):\n",
    "    # Get the path\n",
    "    text_path = os.path.join(text_folder, filename)\n",
    "    print(text_path)\n",
    "\n",
    "    # Open the file\n",
    "    with open(text_path) as file:\n",
    "        text_txt=file.read()\n",
    "\n",
    "    # make nltk version of the text (useful for concordance)\n",
    "    import nltk\n",
    "    text_words = nltk.word_tokenize(text_txt)\n",
    "    text_nltk = nltk.text.Text(text_words)\n",
    "\n",
    "    # get concordance\n",
    "    text_nltk.concordance(word,width=width,lines=lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance(text_folder,'1938.Roosevelt.txt','government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_meta.boxplot('war',by='Party',figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) TF-IDF\n",
    "\n",
    "#### TF: Term Frequency\n",
    "\n",
    "<center><img src=\"https://latex.codecogs.com/png.latex?TF = \\frac{n_w}{n_d}\"></center>\n",
    "\n",
    "Where:\n",
    "* *Nw* is the number of times a given word *w* appears in a document.\n",
    "* *Nd* is the number of words in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a given word?\n",
    "given_word='jobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already have that calculated here:\n",
    "tf_series = dtm[given_word]\n",
    "tf_series.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDF: Inverse Document Frequency\n",
    "\n",
    "<center><img src=\"https://latex.codecogs.com/png.latex?IDF = \\log \\left( \\frac{c_d}{i_d} \\right)\"></center>\n",
    "\n",
    "Where:\n",
    "* <img src=\"https://latex.codecogs.com/png.latex?{c_d}\"> is the count of documents in the corpus.\n",
    "* <img src=\"https://latex.codecogs.com/png.latex?{i_d}\"> = is the number of documents in which that word appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of documents\n",
    "num_docs = len(dtm)\n",
    "num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of documents a given word appears\n",
    "dtm[dtm[given_word]>0][given_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_with_word=len(dtm[dtm[given_word]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "idf = np.log(num_docs/num_docs_with_word)\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_series = tf_series * idf\n",
    "tfidf_series.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'tfidf':tfidf_series, 'tf':tf_series}).plot(x='tf',y='tfidf',kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make\n",
    "def to_tfidf(dtm):\n",
    "    # list of dictionaries\n",
    "    dtm_tfidf = pd.DataFrame()\n",
    "    \n",
    "    for word in dtm.columns:\n",
    "        # tf\n",
    "        tf_series = dtm[word]\n",
    "        \n",
    "        # idf\n",
    "        num_docs = len(dtm)\n",
    "        num_docs_with_word=len(dtm[dtm[word]>0])\n",
    "        idf=np.log(num_docs/num_docs_with_word)\n",
    "        \n",
    "        # tfidf\n",
    "        tfidf_series = tf_series * idf\n",
    "        dtm_tfidf[word]=tfidf_series\n",
    "    \n",
    "    return dtm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf=to_tfidf(dtm)\n",
    "dtm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word='america'\n",
    "dtm[word].nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf[word].nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'tf':dtm[word], 'tfidf':dtm_tfidf[word]}).plot(x='tf',y='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn='2002.Bush.txt'\n",
    "dtm_tfidf.loc[fn].nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.loc[fn].nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn='2017.Trump.txt'\n",
    "dtm_tfidf.loc[fn].nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "for index in reversed(dtm_tfidf.index):\n",
    "    # get row for this index\n",
    "    row=dtm_tfidf.loc[index]\n",
    "    \n",
    "    # get the lagest words\n",
    "    top_words_series=row.nlargest(n_words)\n",
    "    top_words_list=list(top_words_series.index)\n",
    "    top_words_str=', '.join(top_words_list)\n",
    "    \n",
    "    # print\n",
    "    print('##',index.upper())\n",
    "    print(top_words_str)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Fisher's exact test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this we need a document-term matrix *of raw counts*\n",
    "dtm_counts = make_dtm(text_folder,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_counts_meta = df_meta.merge(dtm_counts,on='fn')\n",
    "dtm_counts_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs=dtm_counts[df_meta.Party == 'Republican']\n",
    "Ds=dtm_counts[df_meta.Party == 'Democrat']\n",
    "Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word='immigration'\n",
    "sum_word_Rs = Rs[word].sum()\n",
    "sum_word_Ds = Ds[word].sum()\n",
    "\n",
    "print(sum_word_Rs,sum_word_Ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_allword_Rs=Rs.sum().sum()\n",
    "sum_allword_Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_allword_Ds=Ds.sum().sum()\n",
    "sum_allword_Ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_notword_Rs = sum_allword_Rs - sum_word_Rs\n",
    "sum_notword_Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_notword_Ds = sum_allword_Ds - sum_word_Ds\n",
    "sum_notword_Ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = [\n",
    "    [sum_word_Rs, sum_notword_Rs],\n",
    "    [sum_word_Ds, sum_notword_Ds]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "\n",
    "oddsratio, pvalue = fisher_exact(contingency_table)\n",
    "oddsratio, pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Stacking\" a DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_counts.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_stacked = dtm_counts.stack().reset_index()\n",
    "dtm_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_stacked.columns = ['fn','word','count']\n",
    "dtm_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table back to unstacked original form\n",
    "dtm_stacked.pivot(index='fn',columns='word',values='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stacked DTM with meta\n",
    "dtm_stacked_meta = df_meta.merge(dtm_stacked,on='fn')\n",
    "dtm_stacked_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_word_Rs=dtm_stacked_meta.query('word == \"government\" & Party == \"Republican\"')['count'].sum()\n",
    "num_word_notRs=dtm_stacked_meta.query('word == \"government\" & Party != \"Republican\"')['count'].sum()\n",
    "num_notword_Rs=dtm_stacked_meta.query('word != \"government\" & Party == \"Republican\"')['count'].sum()\n",
    "num_notword_notRs=dtm_stacked_meta.query('word != \"government\" & Party != \"Republican\"')['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = [\n",
    "    [num_word_Rs, num_word_notRs],\n",
    "    [num_notword_Rs, num_notword_notRs]\n",
    "]\n",
    "fisher_exact(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.34 to 1 = the odds of \"carried\" appearing in Republican (vs. non-Republican) texts\n",
      "2.46 to 1 = the odds of \"farmer\" appearing in Republican (vs. non-Republican) texts\n",
      "2.46 to 1 = the odds of \"corporation\" appearing in Republican (vs. non-Republican) texts\n",
      "2.02 to 1 = the odds of \"terrorists\" appearing in Republican (vs. non-Republican) texts\n",
      "4.21 to 1 = the odds of \"territory\" appearing in Republican (vs. non-Republican) texts\n",
      "2.2 to 1 = the odds of \"conduct\" appearing in Republican (vs. non-Republican) texts\n",
      "2.09 to 1 = the odds of \"mexico\" appearing in Republican (vs. non-Republican) texts\n",
      "3.0 to 1 = the odds of \"dealing\" appearing in Republican (vs. non-Republican) texts\n",
      "2.07 to 1 = the odds of \"railroads\" appearing in Republican (vs. non-Republican) texts\n",
      "2.14 to 1 = the odds of \"persons\" appearing in Republican (vs. non-Republican) texts\n",
      "3.83 to 1 = the odds of \"chief\" appearing in Republican (vs. non-Republican) texts\n",
      "2.12 to 1 = the odds of \"practice\" appearing in Republican (vs. non-Republican) texts\n",
      "6.96 to 1 = the odds of \"statute\" appearing in Republican (vs. non-Republican) texts\n",
      "8.79 to 1 = the odds of \"investigation\" appearing in Republican (vs. non-Republican) texts\n",
      "3.04 to 1 = the odds of \"earnestly\" appearing in Republican (vs. non-Republican) texts\n",
      "3.66 to 1 = the odds of \"committee\" appearing in Republican (vs. non-Republican) texts\n",
      "3.16 to 1 = the odds of \"evil\" appearing in Republican (vs. non-Republican) texts\n",
      "2.35 to 1 = the odds of \"submitted\" appearing in Republican (vs. non-Republican) texts\n",
      "2.45 to 1 = the odds of \"organized\" appearing in Republican (vs. non-Republican) texts\n",
      "2.45 to 1 = the odds of \"received\" appearing in Republican (vs. non-Republican) texts\n",
      "2.6 to 1 = the odds of \"expenditure\" appearing in Republican (vs. non-Republican) texts\n",
      "23.44 to 1 = the odds of \"supervision\" appearing in Republican (vs. non-Republican) texts\n",
      "4.84 to 1 = the odds of \"governmental\" appearing in Republican (vs. non-Republican) texts\n",
      "2.69 to 1 = the odds of \"river\" appearing in Republican (vs. non-Republican) texts\n",
      "9.52 to 1 = the odds of \"claims\" appearing in Republican (vs. non-Republican) texts\n",
      "2.53 to 1 = the odds of \"amendment\" appearing in Republican (vs. non-Republican) texts\n",
      "7.16 to 1 = the odds of \"arbitration\" appearing in Republican (vs. non-Republican) texts\n",
      "4.0 to 1 = the odds of \"careful\" appearing in Republican (vs. non-Republican) texts\n",
      "3.01 to 1 = the odds of \"recommendation\" appearing in Republican (vs. non-Republican) texts\n",
      "4.34 to 1 = the odds of \"desirable\" appearing in Republican (vs. non-Republican) texts\n",
      "4.68 to 1 = the odds of \"degree\" appearing in Republican (vs. non-Republican) texts\n",
      "5.07 to 1 = the odds of \"appointed\" appearing in Republican (vs. non-Republican) texts\n",
      "2.05 to 1 = the odds of \"except\" appearing in Republican (vs. non-Republican) texts\n",
      "9.1 to 1 = the odds of \"satisfactory\" appearing in Republican (vs. non-Republican) texts\n",
      "6.92 to 1 = the odds of \"forest\" appearing in Republican (vs. non-Republican) texts\n",
      "2.02 to 1 = the odds of \"honest\" appearing in Republican (vs. non-Republican) texts\n",
      "4.18 to 1 = the odds of \"moreover\" appearing in Republican (vs. non-Republican) texts\n",
      "3.05 to 1 = the odds of \"directed\" appearing in Republican (vs. non-Republican) texts\n",
      "2.85 to 1 = the odds of \"republics\" appearing in Republican (vs. non-Republican) texts\n",
      "2.48 to 1 = the odds of \"pending\" appearing in Republican (vs. non-Republican) texts\n",
      "2.33 to 1 = the odds of \"joint\" appearing in Republican (vs. non-Republican) texts\n",
      "7.69 to 1 = the odds of \"postal\" appearing in Republican (vs. non-Republican) texts\n"
     ]
    }
   ],
   "source": [
    "# Try every word!\n",
    "result_list=[]\n",
    "\n",
    "party='Republican'\n",
    "for word in dtm_stacked_meta['word'].unique():\n",
    "    num_word_Rs=dtm_stacked_meta.query('word == \"'+word+'\" & Party == \"'+party+'\"')['count'].sum()\n",
    "    num_word_notRs=dtm_stacked_meta.query('word == \"'+word+'\" & Party != \"'+party+'\"')['count'].sum()\n",
    "    num_notword_Rs=dtm_stacked_meta.query('word != \"'+word+'\" & Party == \"'+party+'\"')['count'].sum()\n",
    "    num_notword_notRs=dtm_stacked_meta.query('word != \"'+word+'\" & Party != \"'+party+'\"')['count'].sum()\n",
    "    contingency_table = [\n",
    "        [num_word_Rs, num_word_notRs],\n",
    "        [num_notword_Rs, num_notword_notRs]\n",
    "    ]\n",
    "    oddsratio,pvalue=fisher_exact(contingency_table)\n",
    "    if oddsratio>2 and pvalue<0.05:\n",
    "        print('{oddsratio} to 1 = the odds of \"{word}\" appearing in {party} (vs. non-{party}) texts'.format(\n",
    "            word=word,party=party,oddsratio=round(oddsratio,2)))\n",
    "\n",
    "    result_dict={}\n",
    "    result_dict['word']=word\n",
    "    result_dict['oddsratio']=oddsratio\n",
    "    result_dict['pvalue']=pvalue\n",
    "    result_dict['group']=party\n",
    "    result_list.append(result_dict)\n",
    "\n",
    "df_mdw = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>oddsratio</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [group, oddsratio, pvalue, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mdw[df_mdw.group=='Democrat'].sort_values('oddsratio',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>oddsratio</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Republican</td>\n",
       "      <td>29.814889</td>\n",
       "      <td>1.269588e-49</td>\n",
       "      <td>court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Republican</td>\n",
       "      <td>23.439326</td>\n",
       "      <td>1.901514e-19</td>\n",
       "      <td>supervision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Republican</td>\n",
       "      <td>20.029269</td>\n",
       "      <td>1.842075e-31</td>\n",
       "      <td>cent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Republican</td>\n",
       "      <td>14.651442</td>\n",
       "      <td>1.066697e-21</td>\n",
       "      <td>bureau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Republican</td>\n",
       "      <td>13.997990</td>\n",
       "      <td>1.429226e-33</td>\n",
       "      <td>tariff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Republican</td>\n",
       "      <td>10.191117</td>\n",
       "      <td>1.458381e-24</td>\n",
       "      <td>courts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>Republican</td>\n",
       "      <td>9.521590</td>\n",
       "      <td>8.666267e-15</td>\n",
       "      <td>claims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Republican</td>\n",
       "      <td>9.102826</td>\n",
       "      <td>6.863674e-14</td>\n",
       "      <td>satisfactory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Republican</td>\n",
       "      <td>8.789364</td>\n",
       "      <td>4.646844e-15</td>\n",
       "      <td>investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Republican</td>\n",
       "      <td>7.690104</td>\n",
       "      <td>1.390131e-12</td>\n",
       "      <td>postal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Republican</td>\n",
       "      <td>7.284211</td>\n",
       "      <td>1.882482e-23</td>\n",
       "      <td>canal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Republican</td>\n",
       "      <td>7.161276</td>\n",
       "      <td>1.169184e-12</td>\n",
       "      <td>arbitration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Republican</td>\n",
       "      <td>7.051924</td>\n",
       "      <td>3.570370e-21</td>\n",
       "      <td>board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>Republican</td>\n",
       "      <td>6.958081</td>\n",
       "      <td>2.072143e-13</td>\n",
       "      <td>statute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>Republican</td>\n",
       "      <td>6.917009</td>\n",
       "      <td>5.675679e-12</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Republican</td>\n",
       "      <td>6.633157</td>\n",
       "      <td>9.472719e-23</td>\n",
       "      <td>commercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Republican</td>\n",
       "      <td>6.153359</td>\n",
       "      <td>2.660581e-16</td>\n",
       "      <td>panama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Republican</td>\n",
       "      <td>6.077255</td>\n",
       "      <td>1.029565e-31</td>\n",
       "      <td>officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Republican</td>\n",
       "      <td>5.645659</td>\n",
       "      <td>6.271053e-25</td>\n",
       "      <td>islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Republican</td>\n",
       "      <td>5.495535</td>\n",
       "      <td>2.051971e-21</td>\n",
       "      <td>property</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          group  oddsratio        pvalue           word\n",
       "297  Republican  29.814889  1.269588e-49          court\n",
       "907  Republican  23.439326  1.901514e-19    supervision\n",
       "508  Republican  20.029269  1.842075e-31           cent\n",
       "716  Republican  14.651442  1.066697e-21         bureau\n",
       "410  Republican  13.997990  1.429226e-33         tariff\n",
       "536  Republican  10.191117  1.458381e-24         courts\n",
       "918  Republican   9.521590  8.666267e-15         claims\n",
       "972  Republican   9.102826  6.863674e-14   satisfactory\n",
       "871  Republican   8.789364  4.646844e-15  investigation\n",
       "992  Republican   7.690104  1.390131e-12         postal\n",
       "451  Republican   7.284211  1.882482e-23          canal\n",
       "931  Republican   7.161276  1.169184e-12    arbitration\n",
       "509  Republican   7.051924  3.570370e-21          board\n",
       "861  Republican   6.958081  2.072143e-13        statute\n",
       "974  Republican   6.917009  5.675679e-12         forest\n",
       "438  Republican   6.633157  9.472719e-23     commercial\n",
       "637  Republican   6.153359  2.660581e-16         panama\n",
       "243  Republican   6.077255  1.029565e-31       officers\n",
       "320  Republican   5.645659  6.271053e-25        islands\n",
       "403  Republican   5.495535  2.051971e-21       property"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mdw[df_mdw.group=='Republican'].sort_values('oddsratio',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn\n",
       "1904.Roosevelt.txt     0.001377\n",
       "1901.Roosevelt.txt     0.000815\n",
       "1903.Roosevelt.txt     0.000468\n",
       "1905.Roosevelt.txt     0.000438\n",
       "1908.Roosevelt.txt     0.000412\n",
       "1949.Truman.txt        0.000293\n",
       "1913.Wilson.txt        0.000281\n",
       "1990.Bush.txt          0.000259\n",
       "1928.Coolidge.txt      0.000248\n",
       "1957.Eisenhower.txt    0.000240\n",
       "Name: forest, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forest?\n",
    "dtm['forest'].nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Mann-Whitney U test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs=dtm[df_meta.Party=='Republican']\n",
    "Ds=dtm[df_meta.Party=='Democrat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=1517.0, pvalue=0.035799315826459614)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word='forest'\n",
    "x=Rs[word]\n",
    "y=Ds[word]\n",
    "mannwhitneyu(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_stacked_meta.query('Party == \"Republican\" and word==\"forest\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mannwhitney(group1,group2,words=None):\n",
    "    if not words:\n",
    "        words = set(group1.columns) & set(group2.columns)\n",
    "    \n",
    "    result_list=[]\n",
    "    for word in words:\n",
    "        x=group1[word]\n",
    "        y=group2[word]\n",
    "        \n",
    "        mwU, pvalue = mannwhitneyu(x,y)\n",
    "    \n",
    "        result_dict={}\n",
    "        result_dict['word']=word\n",
    "        result_dict['mannwhitney_U']=mwU\n",
    "        result_dict['mannwhitney_pvalue']=pvalue\n",
    "        result_list.append(result_dict)\n",
    "        \n",
    "    return pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mannwhitney=compute_mannwhitney(Rs,Ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 Republicans\n",
    "df_mannwhitney.sort_values('mannwhitney_U',ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 Democrats\n",
    "df_mannwhitney.sort_values('mannwhitney_U',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mannwhitney[df_mannwhitney.word==\"iraq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mdw[df_mdw.word==\"iraq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_meta_T.loc['iraq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mdw.merge(df_mannwhitney,on='word').plot(x='oddsratio',logx=True,y='mannwhitney_U',kind='scatter',figsize=(8,8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
