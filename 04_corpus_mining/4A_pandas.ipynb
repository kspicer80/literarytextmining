{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Mining!\n",
    "\n",
    "In this notebook, we'll learn:\n",
    "\n",
    "* How to use pandas, the \"Python Data Analysis Library\"\n",
    "* How to make basic visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From texts to corpora\n",
    "\n",
    "So far we've worked primarily with individual texts. When we have worked with multiple texts, we've often simply hand-replicated the analysis for each text. The most we've scaled up to automating our analysis on multiple texts is to loop over a list of texts.\n",
    "\n",
    "Starting with this notebook, we're going to move from text analysis to corpus analysis. We'll still do the same kinds of text analysis we've been doing, but this time on many texts, and in such a way that our data analyses can be informed by the *metadata* we've collected on our corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to pandas\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a very powerful software library for data analysis in Python. At the end of the day, though, think of it as **\"Excel for robots\"** (or Excel for Python). In other words, pandas lets Python think in terms of rows and columns. The \"excel sheet\" equivalent for pandas is the **DataFrame**.\n",
    "\n",
    "Pandas can convert actual Excel files into its own dataframes very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use pandas, first import it (it's traditional to import it in this way)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the actual excel file of Harry Potter's metadata to a pandas data frame (\"df\"_potter)\n",
    "df_potter = pd.read_excel('../corpora/harry_potter/metadata.xls')\n",
    "\n",
    "# Show \n",
    "df_potter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the actual excel file of Tropic of Orange's metadata to a pandas data frame\n",
    "df_tropic = pd.read_excel('../corpora/tropic_of_orange/metadata.xls')\n",
    "\n",
    "# Show\n",
    "df_tropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Open your own pandas dataframe from your own corpus (follow examples of above)\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataframe\n",
    "\n",
    "Like an Excel sheet, a Pandas dataframe lets us access particular rows and columns of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the entire data frame\n",
    "df_potter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the columns again?\n",
    "df_potter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the column for the title\n",
    "df_potter['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to get a column\n",
    "df_potter.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make it a list:\n",
    "list(df_potter['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To loop over it:\n",
    "for title in df_potter.title:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Print the column for the narrator in the Tropic of Orange metadata\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Loop over the title column (or equivalent) in your own metadata, and print out the title\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get rows numerically by their index using iloc\n",
    "df_potter.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the last row\n",
    "df_potter.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also SET a name for each row, and then use that as an index\n",
    "df_potter.set_index('fn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row for the Goblet of Fire\n",
    "df_potter.set_index('fn').loc['Goblet of Fire.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Get the row for the 30th chapter in Tropic of Orange\n",
    "#\n",
    "\n",
    "df_tropic.iloc[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Get the row for the 4th text in your corpus\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Set the index on Tropic of Orange's dataframe to be the filename\n",
    "# Then get the row for ch14.txt\n",
    "#\n",
    "\n",
    "df_tropic.set_index('fn').loc['ch14.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows/columns\n",
    "\n",
    "The real power of pandas is that we can do filters quite easily. For instance, what if we want all the rows in the Tropic of Orange spreadsheet which are narrated by a particular character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the entire Tropic of Orange data again\n",
    "df_tropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the narrator column\n",
    "df_tropic.narrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when we ask if the narrator is Emi?\n",
    "\n",
    "df_tropic.narrator == 'Emi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can call this sequence something\n",
    "chapter_narrated_by_emi = df_tropic.narrator == 'Emi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we put this sequence of True/Falses inside the bracket notation for the dataframe...\n",
    "df_tropic[ chapter_narrated_by_emi ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...Then we see only those rows narrated by Emi.\n",
    "\n",
    "# The above is equivalent to:\n",
    "df_tropic[ df_tropic.narrator == 'Emi' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can call this filtered version of the data frame something\n",
    "df_tropic_emi = df_tropic[ df_tropic.narrator == 'Emi' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then get the filenames just for Emi's chapters\n",
    "df_tropic_emi.fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is useful because then we can loop over an do things just to Emi's files:\n",
    "for filename in df_tropic_emi.fn:\n",
    "    # do something here!\n",
    "    print(filename,'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Filter the dataframe to show only Buzzworm's chapters\n",
    "#\n",
    "\n",
    "df_tropic[df_tropic.narrator == 'Buzzworm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Filter the dataframe for 'part_title' as 'Artificial Intelligence'\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO: Filter the dataframe for your own corpus in an interesting way\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows NOT narrated by Emi\n",
    "df_tropic[ df_tropic.narrator != 'Emi' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows narrated by Emi or Gabriel\n",
    "narrators_I_want = ['Emi','Gabriel Balboa']\n",
    "\n",
    "df_tropic[ df_tropic.narrator.isin(narrators_I_want) ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows NOT narrated by Emi or Gabriel\n",
    "df_tropic[ ~df_tropic.narrator.isin(narrators_I_want) ]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other dataframe methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns are in the dataframe?\n",
    "\n",
    "df_tropic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if I want to see all unique values of a column?\n",
    "\n",
    "df_tropic.narrator.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if I want to see how many times these unique values occur?\n",
    "\n",
    "df_tropic.narrator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often does each setting occur?\n",
    "df_tropic.setting.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort a dataframe by its values\n",
    "df_potter.sort_values('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by two columns\n",
    "df_tropic.sort_values(['narrator','part'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order matters\n",
    "df_tropic.sort_values(['part','narrator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data + metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data the pandas way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(filename):\n",
    "    with open(filename) as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_punct(token):\n",
    "    if token[0].isalpha():\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text,keep_punct=True):\n",
    "    import nltk\n",
    "    tokens=nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    tokens_nopunct=[]\n",
    "    for token in tokens:\n",
    "        # if punctuation?\n",
    "        if not is_punct(token):\n",
    "            tokens_nopunct.append(token)\n",
    "    \n",
    "    return tokens_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(tokens):\n",
    "    from collections import Counter\n",
    "    return Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(tokens):\n",
    "    counts=count(tokens)\n",
    "    num_words=len(tokens)\n",
    "    for word in counts:\n",
    "        counts[word] = counts[word] / num_words\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief side-note on 'os'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating System (os) functions\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print working directory (the terminal way)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The equivalent to ls:\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a variable to the folder where the harry potter files are stored\n",
    "textfolder_potter = '../corpora/harry_potter/texts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The equivalent to ls [some folder]: we get a list of the files\n",
    "os.listdir(textfolder_potter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can loop over that list\n",
    "for filename in os.listdir(textfolder_potter):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the full path, though, we need to join the FOLDER name to the FILE name\n",
    "\n",
    "# the folder of texts\n",
    "print(textfolder_potter)\n",
    "\n",
    "# a filename in that folder\n",
    "print(filename)\n",
    "\n",
    "# full path = folder + file\n",
    "os.path.join(textfolder_potter, filename)   # use os.path.join(folder, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remind ourselves what this looks\n",
    "df_potter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "textfolder_potter = '../corpora/harry_potter/texts/'\n",
    "\n",
    "# make empty results list\n",
    "results=[]\n",
    "\n",
    "# loop over the filenames\n",
    "for fn in df_potter.fn:\n",
    "    text_path = os.path.join(textfolder_potter, fn)\n",
    "    \n",
    "    # read file to string\n",
    "    text_str = read(text_path)\n",
    "    \n",
    "    # tokenize string to list\n",
    "    text_tokens = tokenize(text_str)\n",
    "    \n",
    "    # count list to dictionary\n",
    "    text_counts = count(text_tokens)\n",
    "    text_tf = tf(text_tokens)\n",
    "    \n",
    "    # make a new result dictionary, always include the filename!\n",
    "    text_results = {'fn':fn}\n",
    "    \n",
    "    # let's add our results\n",
    "    text_results['count_Harry'] = text_counts.get('harry',0)\n",
    "    text_results['count_Hermione'] = text_counts.get('hermione',0)\n",
    "    text_results['count_Ron'] = text_counts.get('ron',0)\n",
    "    \n",
    "    text_results['tf_Harry'] = text_tf.get('harry',0)\n",
    "    text_results['tf_Hermione'] = text_tf.get('hermione',0)\n",
    "    text_results['tf_Ron'] = text_tf.get('ron',0)\n",
    "    text_results['tf_Voldemort'] = text_tf.get('voldemort',0)\n",
    "    \n",
    "    # print the results\n",
    "    print(text_results)\n",
    "    \n",
    "    # add our results to the master results list\n",
    "    results.append(text_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can make a dataframe for just our results\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Show\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set the index to filename also\n",
    "df_results = df_results.set_index('fn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort our results\n",
    "df_results.sort_values('tf_Harry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort our results\n",
    "df_results.sort_values('tf_Harry',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort our results\n",
    "df_results.sort_values('tf_Hermione',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort our results\n",
    "df_results.sort_values('tf_Ron',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining data to metadata\n",
    "\n",
    "Here's a major payoff of using pandas to store our results. We can join them easily with our metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's our metadata again\n",
    "df_potter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's our data again\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's join them!\n",
    "df_potter.join(df_results,on='fn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a meta df with both metadata and data\n",
    "df_all = df_potter.join(df_results,on='fn')\n",
    "\n",
    "# show\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.plot(x='series_num',y='tf_Harry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.plot(x='series_num',y='tf_Hermione')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.plot(x='series_num',y='tf_Ron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.plot(x='series_num',y='tf_Voldemort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_all.plot(x='series_num',y='tf_Harry', ax=ax)\n",
    "df_all.plot(x='series_num',y='tf_Hermione', ax=ax)\n",
    "df_all.plot(x='series_num',y='tf_Ron', ax=ax)\n",
    "df_all.plot(x='series_num',y='tf_Voldemort', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## @TODO: Calculate the words per sentence and commas per sentence for each Harry Potter novel\n",
    "# and visualize the results.\n",
    "# \n",
    "# Please do not edit the results dataframe above but make a new results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
